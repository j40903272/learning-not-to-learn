{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.backends import cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from option import get_option, parser\n",
    "from trainer import Trainer\n",
    "from utils import save_option\n",
    "import data_loader\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "#logging.getLogger().setLevel(logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 87\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urlnet_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_word_freq = 10\n",
    "max_len_words = 200\n",
    "max_len_chars = 200\n",
    "max_len_subwords = 20\n",
    "delimit_mode = 1\n",
    "dev_pct = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/06/2019 11:01:26 - WARNING - tensorflow -   From /host/Proxy/learning-not-to-learn/urlnet_utils.py:113: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "11/06/2019 11:01:26 - WARNING - tensorflow -   From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "11/06/2019 11:01:26 - WARNING - tensorflow -   From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-81cf1f91e60f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhigh_freq_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmin_word_freq\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_reverse_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_word_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_word_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mhigh_freq_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_reverse_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of words with freq >={}: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_word_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhigh_freq_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/host/Proxy/learning-not-to-learn/urlnet_utils.py\u001b[0m in \u001b[0;36mget_word_vocab\u001b[0;34m(urls, max_length_words, min_word_freq)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mvocab_processor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVocabularyProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_frequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_word_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished build vocabulary and mapping to x in {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mvocab_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \"\"\"\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0mword_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_document_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_document_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "urls, labels = read_data(\"../taipei/out.csv\")\n",
    "\n",
    "high_freq_words = None\n",
    "if min_word_freq > 0:\n",
    "    x1, word_reverse_dict = get_word_vocab(urls, max_len_words, min_word_freq) \n",
    "    high_freq_words = sorted(list(word_reverse_dict.values()))\n",
    "    print(\"Number of words with freq >={}: {}\".format(min_word_freq, len(high_freq_words)))\n",
    "\n",
    "x, word_reverse_dict = get_word_vocab(urls, max_len_words)\n",
    "word_x = get_words(x, word_reverse_dict, delimit_mode, urls)\n",
    "ngramed_id_x, ngrams_dict, worded_id_x, words_dict = ngram_id_x(word_x, max_len_subwords, high_freq_words)\n",
    "reverse_dict = {words_dict[i]:i for i in words_dict}\n",
    "chars_dict = ngrams_dict\n",
    "chared_id_x = char_id_x(urls, chars_dict, max_len_chars)\n",
    "print(\"Overall Mal/Ben rate: {}/{}\".format(np.sum(labels==0), np.sum(labels==1)))\n",
    "\n",
    "######## balance ################\n",
    "nmal = (labels==0).sum()\n",
    "nbeg = (labels==1).sum()\n",
    "total = min(nmal, nbeg)-1\n",
    "mal_idx = np.argsort((labels==1))[:nmal]\n",
    "beg_idx = np.argsort((labels==0))[:nbeg]\n",
    "\n",
    "train = np.concatenate([mal_idx[:total], beg_idx[:total]])\n",
    "test = np.concatenate([mal_idx[total:], beg_idx[total:]])\n",
    "assert len(np.unique(labels[test])) > 1\n",
    "assert len(np.unique(labels[train])) > 1\n",
    "\n",
    "\n",
    "########  shuffle & split  ######\n",
    "# shuffle_idx = np.random.permutation(np.arange(len(labels)))\n",
    "# train, test = prep_train_test(len(labels), dev_pct)\n",
    "np.random.shuffle(train)\n",
    "np.random.shuffle(test)\n",
    "y_train, y_val = labels[train], labels[test]\n",
    "\n",
    "\n",
    "\n",
    "#x_train_char = ngramed_id_x[train]\n",
    "#x_val_char = ngramed_id_x[test]\n",
    "x_train_word = pad_seq_in_word(worded_id_x[train], max_len_words)\n",
    "x_val_word = pad_seq_in_word(worded_id_x[test], max_len_words)\n",
    "#x_train_char_seq = pad_seq_in_word(chared_id_x[train], max_len_chars)\n",
    "#x_val_char_seq = pad_seq_in_word(chared_id_x[test], max_len_chars)\n",
    "print(x_train_word.shape, x_val_word.shape)\n",
    "#print(x_train_char_seq.shape, x_val_char_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(word_x, labels):\n",
    "    if not os.path.isfile(\"word_mal_ratio_large.pkl\"):\n",
    "        df_tmp = pd.DataFrame({'token':word_x, \"label\":labels})\n",
    "        word_mal_ratio = dict()\n",
    "\n",
    "        for word in tqdm(words_dict):\n",
    "            df_tmp['exist'] = df_tmp['token'].map(lambda x:word in x)\n",
    "            cnt = len(df_tmp.query('exist == True & label == 0'))\n",
    "            word_mal_ratio[word] = cnt / df_tmp.exist.sum()\n",
    "\n",
    "        with open(\"word_mal_ratio_large.pkl\", \"wb\") as f:\n",
    "            pickle.dump(word_mal_ratio, f)\n",
    "    else:\n",
    "        with open(\"word_mal_ratio_large.pkl\", \"rb\") as f:\n",
    "            word_mal_ratio = pickle.load(f)\n",
    "\n",
    "\n",
    "    tmp = [word_mal_ratio[i] for i in word_mal_ratio]\n",
    "    tmp = pd.DataFrame({'word_mal_ratio':tmp, 'word':[i for i in word_mal_ratio]})\n",
    "    #tmp.plot(kind='hist')\n",
    "    return word_mal_ratio, tmp\n",
    "  \n",
    "\n",
    "# from multiprocessing.pool import ThreadPool\n",
    "# pool = ThreadPool(processes=4)\n",
    "\n",
    "# async_result = pool.apply_async(foo, (word_x, labels))\n",
    "# word_mal_ratio, tmp = async_result.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_mal_ratio, tmp = foo(word_x, labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# from pandarallel import pandarallel\n",
    "# pandarallel.initialize(nb_workers=1)\n",
    "\n",
    "if not os.path.isfile(\"word_mal_ratio_large.pkl\"):\n",
    "    df_tmp = pd.DataFrame({'token':word_x, \"label\":labels})\n",
    "    word_mal_ratio = dict()\n",
    "\n",
    "    for word in tqdm(words_dict):\n",
    "        df_tmp['exist'] = df_tmp['token'].map(lambda x:word in x)\n",
    "        cnt = len(df_tmp.query('exist == True & label == 0'))\n",
    "        word_mal_ratio[word] = cnt / df_tmp.exist.sum()\n",
    "    \n",
    "    with open(\"word_mal_ratio.pkl\", \"wb\") as f:\n",
    "        pickle.dump(word_mal_ratio, f)\n",
    "else:\n",
    "    with open(\"word_mal_ratio_large.pkl\", \"rb\") as f:\n",
    "        word_mal_ratio = pickle.load(f)\n",
    "\n",
    "\n",
    "tmp = [word_mal_ratio[i] for i in word_mal_ratio]\n",
    "tmp = pd.DataFrame({'word_mal_ratio':tmp, 'word':[i for i in word_mal_ratio]})\n",
    "tmp.plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = words_dict\n",
    "tmp2 = ngrams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls, labels = read_data(\"../URLNet/val_10000.txt\")\n",
    "x, word_reverse_dict = get_word_vocab(urls, max_len_words) \n",
    "word_x = get_words(x, word_reverse_dict, delimit_mode, urls) \n",
    "ngramed_id_x, worded_id_x = ngram_id_x_from_dict(word_x, max_len_subwords, ngrams_dict, words_dict) \n",
    "chared_id_x = char_id_x(urls, chars_dict, max_len_chars)\n",
    "print(\"Number of testing urls: {}\".format(len(labels)))\n",
    "\n",
    "y_test = labels\n",
    "#x_test_char = ngramed_id_x\n",
    "x_test_word = pad_seq_in_word(worded_id_x, max_len_words)\n",
    "#x_test_char_seq = pad_seq_in_womax_len_words_id_x, max_len_chars)\n",
    "print(len(x_test_word))#, x_test_char_seq.shape, x_test_char_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tmp1 == words_dict\n",
    "assert tmp2 == ngrams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls, labels = read_data(\"../URLNet/train_10000.txt\")#\"../URLNet/test_10000.txt\"\n",
    "x, word_reverse_dict = get_word_vocab(urls, max_len_words) \n",
    "word_x = get_words(x, word_reverse_dict, delimit_mode, urls) \n",
    "ngramed_id_x, worded_id_x = ngram_id_x_from_dict(word_x, max_len_subwords, ngrams_dict, words_dict)\n",
    "chared_id_x = char_id_x(urls, chars_dict, max_len_chars)\n",
    "print(\"Number of testing urls: {}\".format(len(labels)))\n",
    "\n",
    "y_test2 = labels\n",
    "#x_test_char2 = ngramed_id_x\n",
    "x_test_word2 = pad_seq_in_word(worded_id_x, max_len_words)\n",
    "#x_test_char_seq2 = pad_seq_in_word(chared_id_x, max_len_chars)\n",
    "print(len(x_test_word2))#, x_test_char_seq2.shape, x_test_char_seq2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tmp1 == words_dict\n",
    "assert tmp2 == ngrams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 32\n",
    "l2_reg_lambda = 0.0\n",
    "emb_mode = 2\n",
    "filter_size = [3,4,5,6]\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class mydata(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "\n",
    "train_dataset = mydata(x_train_word, y_train)\n",
    "val_dataset = mydata(x_val_word, y_val)\n",
    "test_dataset1 = mydata(x_test_word, y_test)\n",
    "test_dataset2 = mydata(x_test_word2, y_test2)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader1 = DataLoader(test_dataset1, batch_size=batch_size, shuffle=False)\n",
    "test_loader2 = DataLoader(test_dataset2, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_word_ratio = pd.read_csv(\"../URLNet/word_mal_ratio.csv\")\n",
    "df_word_ratio.plot(kind='hist')\n",
    "df_word_ratio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_thresh_sum(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True):\n",
    "    y_pred = F.sigmoid(y_pred)\n",
    "    return ((y_pred>thresh)==y_true.byte()).float().sum().item()\n",
    "\n",
    "def accuracy_thresh_score(y_pred, y_true, thresh:float=0.5):\n",
    "    return ((y_pred>0.5).astype(int) == y_true).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_cross_entropy(inp, target, size_average=True):\n",
    "    if size_average:\n",
    "        return torch.mean(torch.sum(-target * F.log_softmax(inp), dim=1))\n",
    "    else:\n",
    "        return torch.sum(torch.sum(-target * F.log_softmax(inp), dim=1))\n",
    "\n",
    "class NegativeEntropyLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NegativeEntropyLoss, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b = F.softmax(x, dim=1) * F.log_softmax(x, dim=1)\n",
    "        b = -1.0 * b.sum()\n",
    "        return b\n",
    "\n",
    "def special_loss(target):\n",
    "    target = F.softmax(target, dim=1)\n",
    "    return torch.mean(torch.sum(target*torch.log(target), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.WordCNN(\n",
    "            word_ngram_vocab_size = len(words_dict)+1,\n",
    "            emb_size=emb_dim,\n",
    "            word_seq_len=max_len_words,\n",
    "            l2_reg_lambda=l2_reg_lambda,\n",
    "            kernel_sizes=filter_size).cuda()\n",
    "\n",
    "print('paramters count', sum(p.numel() for p in model.parameters()))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(model, optimizer, loader, train=True, message=\"\"):\n",
    "    loss_total = 0\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    \n",
    "    model.train() if train else model.eval()\n",
    "    mode = torch.enable_grad if train else torch.no_grad\n",
    "    \n",
    "    with mode():\n",
    "        for (data, label) in tqdm(loader, desc=message):\n",
    "            data, label = data.long().cuda(), label.float().cuda()\n",
    "            logits = model(data).squeeze()\n",
    "            loss = F.binary_cross_entropy_with_logits(logits, label, reduction=\"mean\")\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            loss_total += loss.item()\n",
    "            all_labels.append(label.detach().cpu().numpy())\n",
    "            all_logits.append(F.sigmoid(logits).detach().cpu().numpy())\n",
    "            \n",
    "            \n",
    "    loss_total /= len(loader)\n",
    "    all_labels = np.hstack(all_labels)\n",
    "    all_logits = np.hstack(all_logits)\n",
    "    auc = roc_auc_score(all_labels, all_logits) if len(np.unique(all_labels)) > 1 else 0\n",
    "    acc = accuracy_thresh_score(all_logits, all_labels)\n",
    "    \n",
    "    #logger.info(message)\n",
    "    logger.info('Loss     : {}'.format(loss_total))\n",
    "    logger.info('Accuracy : {}'.format(acc))\n",
    "    logger.info('AUC      : {}'.format(auc))\n",
    "    \n",
    "    return {'loss':loss_total, 'acc':acc, 'auc':auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start straining\n",
    "\n",
    "history = {'train':[], 'valid':[], 'test1':[], 'test2':[]}\n",
    "for e in tqdm(range(10), desc=\"Epoch\"):\n",
    "    train_result = step(model, optimizer, train_loader, train=True, message=\"Training :{}\".format(e))\n",
    "    valid_result = step(model, optimizer, val_loader, train=False, message=\"Validation :{}\".format(e))\n",
    "    test_result1 = step(model, optimizer, test_loader1, train=False, message=\"Test 1 :{}\".format(e))\n",
    "    test_result2 = step(model, optimizer, test_loader2, train=False, message=\" Test 2:{}\".format(e)) # org train\n",
    "    \n",
    "    history['train'].append(train_result)\n",
    "    history['valid'].append(valid_result)\n",
    "    history['test1'].append(test_result1)\n",
    "    history['test2'].append(test_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = \"baseline-large\"\n",
    "\n",
    "train_loss = [l['loss'] for l in history['train']]\n",
    "valid_loss = [l['loss'] for l in history['valid']]\n",
    "test1_loss = [l['loss'] for l in history['test1']]\n",
    "test2_loss = [l['loss'] for l in history['test2']]\n",
    "\n",
    "train_auc = [l['auc'] for l in history['train']]\n",
    "valid_auc = [l['auc'] for l in history['valid']]\n",
    "test1_auc = [l['auc'] for l in history['test1']]\n",
    "test2_auc = [l['auc'] for l in history['test2']]\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.title('Loss')\n",
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(valid_loss, label='valid')\n",
    "plt.plot(test1_loss, label='test1')\n",
    "plt.plot(test2_loss, label='test2')\n",
    "plt.legend()\n",
    "if save:\n",
    "    path = os.path.join(\"output\", save+'_loss.png')\n",
    "    plt.savefig(path)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.title('AUC Score')\n",
    "plt.plot(train_auc, label='train')\n",
    "plt.plot(valid_auc, label='valid')\n",
    "plt.plot(test1_auc, label='test1')\n",
    "plt.plot(test2_auc, label='test2')\n",
    "plt.legend()\n",
    "if save:\n",
    "    path = os.path.join(\"output\", save+'_auc.png')\n",
    "    plt.savefig(path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNKId = words_dict['<UNKNOWN>']\n",
    "word_mal_ratio['<UNKNOWN>'] = 0.5\n",
    "data = list(map(lambda x:words_dict.get(x, UNKId), word_mal_ratio.keys()))\n",
    "label = list(map(lambda x:np.array([x, 1-x]), word_mal_ratio.values()))\n",
    "\n",
    "emb_ratio_dataset = mydata(data, label)\n",
    "emb_ratio_loader = DataLoader(emb_ratio_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, l = next(iter(emb_ratio_loader))\n",
    "d.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_step(model, optimizer, train=False, iters=1):\n",
    "    \n",
    "    loader = emb_ratio_loader\n",
    "    loss_total = 0\n",
    "    _lambda = 0.1\n",
    "    \n",
    "    model.train() if train else model.eval()\n",
    "    mode = torch.enable_grad if train else torch.no_grad\n",
    "    with mode():\n",
    "        for _ in range(iters):\n",
    "            for (data, label) in loader:\n",
    "            #for (data, label) in tqdm(loader, desc=\"emb bias\"):\n",
    "                data, label = data.long().unsqueeze(1).cuda(), label.float().cuda()\n",
    "                logits = model(data)\n",
    "                loss = soft_cross_entropy(logits, label, size_average=True) * _lambda\n",
    "                if train:\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                loss_total += loss.item()\n",
    "                \n",
    "    loss_total /= (len(loader)*iters/batch_size)\n",
    "    return loss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_step(model, optimizer, loader, train=True, message=\"\"):\n",
    "    loss_total = 0\n",
    "    bias_loss_total = 0\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    \n",
    "    model.train() if train else model.eval()\n",
    "    bias_model.train if train else bias_model.eval()\n",
    "    mode = torch.enable_grad if train else torch.no_grad\n",
    "    \n",
    "    with mode():\n",
    "        for (data, label) in tqdm(loader, desc=message):\n",
    "            data, label = data.long().cuda(), label.float().cuda()\n",
    "            logits = model(data).squeeze()\n",
    "            loss = F.binary_cross_entropy_with_logits(logits, label, reduction=\"sum\")\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            loss_total += loss.item()\n",
    "            all_labels.append(label.detach().cpu().numpy())\n",
    "            all_logits.append(F.sigmoid(logits).detach().cpu().numpy())\n",
    "            \n",
    "#             ###adv step for each original batch\n",
    "#             logits = bias_model(data).squeeze()\n",
    "#             _lambda = 0.01\n",
    "#             bias_loss = _lambda * soft_cross_entropy(logits)\n",
    "#             if train:\n",
    "#                 bias_loss.backward()\n",
    "#                 bias__optimizer.step()\n",
    "#                 bias__optimizer.zero_grad()\n",
    "#             bias_loss_total += bias_loss.item()\n",
    "#     bias_loss_total = bias_loss_total/(len(loader)/batch_size\n",
    "    \n",
    "    loss_total /= (len(loader)/batch_size)\n",
    "    all_labels = np.hstack(all_labels)\n",
    "    all_logits = np.hstack(all_logits)\n",
    "    auc = roc_auc_score(all_labels, all_logits) if len(np.unique(all_labels)) > 1 else 0\n",
    "    acc = accuracy_thresh_score(all_logits, all_labels)\n",
    "    \n",
    "\n",
    "    bias_loss_total = emb_step(bias_model, bias_optimizer, train, 1)\n",
    "    logger.info('Loss     : {}'.format(loss_total))\n",
    "    logger.info('Bias Loss: {}'.format(bias_loss_total))\n",
    "    logger.info('Accuracy : {}'.format(acc))\n",
    "    logger.info('AUC      : {}'.format(auc))\n",
    "    \n",
    "    return {'loss':loss_total, 'acc':acc, 'auc':auc, \"bias\":bias_loss_total}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_model = models.WordCNN(\n",
    "            word_ngram_vocab_size = len(words_dict)+1,\n",
    "            emb_size=emb_dim,\n",
    "            word_seq_len=max_len_words,\n",
    "            l2_reg_lambda=l2_reg_lambda,\n",
    "            kernel_sizes=filter_size).cuda()\n",
    "adv_optimizer = torch.optim.Adam(adv_model.parameters(), lr=1e-3)\n",
    "\n",
    "bias_model = models.BiasPredictor(adv_model.word_emb, emb_dim).cuda()\n",
    "bias_optimizer = torch.optim.Adam(bias_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start straining\n",
    "\n",
    "history = {'train':[], 'valid':[], 'test1':[], 'test2':[]}\n",
    "for e in tqdm(range(10), desc=\"Epoch\"):\n",
    "    train_result = adv_step(adv_model, adv_optimizer, train_loader, train=True, message=\"Training :{}\".format(e))\n",
    "    valid_result = adv_step(adv_model, adv_optimizer, val_loader, train=False, message=\"Validation :{}\".format(e))\n",
    "    test_result1 = adv_step(adv_model, adv_optimizer, test_loader1, train=False, message=\"Test 1 :{}\".format(e))\n",
    "    test_result2 = adv_step(adv_model, adv_optimizer, test_loader2, train=False, message=\"Test 2 :{}\".format(e))\n",
    "    \n",
    "    history['train'].append(train_result)\n",
    "    history['valid'].append(valid_result)\n",
    "    history['test1'].append(test_result1)\n",
    "    history['test2'].append(test_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = \"adv\"\n",
    "\n",
    "train_loss = [l['loss'] for l in history['train']]\n",
    "valid_loss = [l['loss'] for l in history['valid']]\n",
    "test1_loss = [l['loss'] for l in history['test1']]\n",
    "test2_loss = [l['loss'] for l in history['test2']]\n",
    "\n",
    "train_bloss = [l['bias'] for l in history['train']]\n",
    "valid_bloss = [l['bias'] for l in history['valid']]\n",
    "test1_bloss = [l['bias'] for l in history['test1']]\n",
    "test2_bloss = [l['bias'] for l in history['test2']]\n",
    "\n",
    "train_auc = [l['auc'] for l in history['train']]\n",
    "valid_auc = [l['auc'] for l in history['valid']]\n",
    "test1_auc = [l['auc'] for l in history['test1']]\n",
    "test2_auc = [l['auc'] for l in history['test2']]\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.title('Loss')\n",
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(valid_loss, label='valid')\n",
    "plt.plot(test1_loss, label='test1')\n",
    "plt.plot(test2_loss, label='test2')\n",
    "plt.legend()\n",
    "if save:\n",
    "    path = os.path.join(\"output\", save+'_loss.png')\n",
    "    plt.savefig(path)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.title('Bias Loss')\n",
    "plt.plot(train_bloss, label='train')\n",
    "plt.plot(valid_bloss, label='valid')\n",
    "plt.plot(test1_bloss, label='test1')\n",
    "plt.plot(test2_bloss, label='test2')\n",
    "plt.legend()\n",
    "if save:\n",
    "    path = os.path.join(\"output\", save+'_bias_loss.png')\n",
    "    plt.savefig(path)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.title('AUC Score')\n",
    "plt.plot(train_auc, label='train')\n",
    "plt.plot(valid_auc, label='valid')\n",
    "plt.plot(test1_auc, label='test1')\n",
    "plt.plot(test2_auc, label='test2')\n",
    "plt.legend()\n",
    "if save:\n",
    "    path = os.path.join(\"output\", save+'_auc.png')\n",
    "    plt.savefig(path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in tqdm(range(1), desc=\"Epoch\"):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    train_acc = 0\n",
    "    val_acc = 0\n",
    "    train_auc = 0\n",
    "    val_auc = 0\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    \n",
    "    model.train()\n",
    "    for (data, label) in tqdm(train_loader, desc=\"Iteration\"):\n",
    "        data, label = data.long().cuda(), label.float().cuda()\n",
    "        logits = model(data).squeeze()\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "        all_labels.append(label.detach().cpu().numpy())\n",
    "        all_logits.append(F.sigmoid(logits).detach().cpu().numpy())\n",
    "    \n",
    "    all_labels = np.hstack(all_labels)\n",
    "    all_logits = np.hstack(all_logits)\n",
    "    train_auc = roc_auc_score(all_labels, all_logits)\n",
    "    train_acc = accuracy_thresh_score(logits, label)\n",
    "\n",
    "    \n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    model.eval()\n",
    "    for (data, label) in tqdm(test_loader, desc=\"Evaluation\"):\n",
    "        data, label = data.long().cuda(), label.float().cuda()\n",
    "        with torch.no_grad():\n",
    "            logits = model(data).squeeze()\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, label)\n",
    "        val_loss += loss.item()\n",
    "        all_labels.append(label.detach().cpu().numpy())\n",
    "        all_logits.append(F.sigmoid(logits).detach().cpu().numpy())\n",
    "        \n",
    "    all_labels = np.hstack(all_labels)\n",
    "    all_logits = np.hstack(all_logits)\n",
    "    val_auc = roc_auc_score(all_labels, all_logits)\n",
    "    val_acc = accuracy_thresh_score(logits, label)\n",
    "\n",
    "    \n",
    "    \n",
    "    logger.info('Training   Loss     : {}'.format(train_loss/(len(train_loader)/batch_size)))\n",
    "    logger.info('Training   Accuracy : {}'.format(train_acc/len(train_loader)))\n",
    "    logger.info('Training   AUC      : {}'.format(train_auc))\n",
    "    \n",
    "    logger.info('Validation Loss     : {}'.format(val_loss/(len(test_loader)/batch_size)))\n",
    "    logger.info('Validation Accuracy : {}'.format(val_acc/len(test_loader)))\n",
    "    logger.info('Validation AUC      : {}'.format(val_auc))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class DADATrainer(object):\n",
    "    def __init__(self, option):\n",
    "        self.option = option\n",
    "\n",
    "        self._build_model()\n",
    "        self._set_optimizer()\n",
    "        self.logger = logger_setting(option.exp_name, option.save_dir, option.debug)\n",
    "\n",
    "    def _build_model(self):\n",
    "        self.n_color_cls = 8\n",
    "\n",
    "        self.net = models.WordCNN(vocab_size, word_seq_len, emb_size, l2_reg_lambda)\n",
    "        self.pred_net = models.BiasPredictor(num_filters_total)\n",
    "\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss(ignore_index=255)\n",
    "        self.bias_loss = nn.CrossEntropyLoss(ignore_index=255)\n",
    "\n",
    "\n",
    "        if self.option.cuda:\n",
    "            self.net.cuda()\n",
    "            self.pred_net.cuda()\n",
    "            self.loss.cuda()\n",
    "            self.bias_loss.cuda()\n",
    "\n",
    "    def _set_optimizer(self):\n",
    "        self.optim = optim.SGD(filter(lambda p: p.requires_grad, self.net.parameters()), lr=self.option.lr, momentum=self.option.momentum, weight_decay=self.option.weight_decay)\n",
    "        self.optim_bias = optim.SGD(self.pred_net.parameters(), lr=self.option.lr, momentum=self.option.momentum, weight_decay=self.option.weight_decay)\n",
    "\n",
    "\n",
    "        #TODO: last_epoch should be the last step of loaded model\n",
    "        lr_lambda = lambda step: self.option.lr_decay_rate ** (step // self.option.lr_decay_period)\n",
    "        self.scheduler = optim.lr_scheduler.LambdaLR(self.optim, lr_lambda=lr_lambda, last_epoch=-1)\n",
    "        self.scheduler_bias = optim.lr_scheduler.LambdaLR(self.optim_r, lr_lambda=lr_lambda, last_epoch=-1)\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def _weights_init(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            m.weight.data.fill_(1.0)\n",
    "            m.bias.data.zero_()\n",
    "\n",
    "    def _initialization(self):\n",
    "        self.net.apply(self._weights_init)\n",
    "\n",
    "\n",
    "        if self.option.is_train and self.option.use_pretrain:\n",
    "            if self.option.checkpoint is not None:\n",
    "                self._load_model()\n",
    "            else:\n",
    "                print(\"Pre-trained model not provided\")\n",
    "\n",
    "\n",
    "\n",
    "    def _mode_setting(self, is_train=True):\n",
    "        if is_train:\n",
    "            self.net.train()\n",
    "            self.pred_net_bias.train()\n",
    "        else:\n",
    "            self.net.eval()\n",
    "            self.pred_net_bias.eval()\n",
    "\n",
    "\n",
    "\n",
    "    def _train_step(self, data_loader, step):\n",
    "        _lambda = 0.01\n",
    "\n",
    "        for i, (images,color_labels,labels) in enumerate(data_loader):\n",
    "            # data\n",
    "            images = self._get_variable(images)\n",
    "            color_labels = self._get_variable(color_labels)\n",
    "            labels = self._get_variable(labels)\n",
    "\n",
    "            # predict labels\n",
    "            self.optim.zero_grad()\n",
    "            self.optim_bias.zero_grad()\n",
    "\n",
    "            feat_label, pred_label = self.net(images)\n",
    "            # predict colors from feat_label. Their prediction should be uniform.\n",
    "            _,pseudo_pred_bias = self.pred_net_bias(feat_label)\n",
    "\n",
    "            # loss for self.net\n",
    "            loss_pred = self.loss(pred_label, torch.squeeze(labels))\n",
    "            loss_pseudo_pred_bias = torch.mean(torch.sum(pseudo_pred_bias*torch.log(pseudo_pred_bias),1))\n",
    "            loss = loss_pred + loss_pseudo_pred_bias*_lambda\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # predict bias\n",
    "            self.optim.zero_grad()\n",
    "            self.optim_bias.zero_grad()\n",
    "\n",
    "            feat_label, pred_label = self.net(images)\n",
    "            feat_color = grad_reverse(feat_label)\n",
    "            pred_bias,_ = self.pred_net_bias(feat_color)\n",
    "\n",
    "\n",
    "            # loss for rgb predictors\n",
    "            loss_pred_bias = self.color_loss(pred_bias, color_labels)\n",
    "            loss_pred_bias.backward()\n",
    "            self.optim.step()\n",
    "            self.optim_bias.step()\n",
    "\n",
    "\n",
    "            if i % self.option.log_step == 0:\n",
    "                msg = \"[TRAIN] cls loss : %.6f, rgb : %.6f, MI : %.6f  (epoch %d.%02d)\" \\\n",
    "                       % (loss_pred, loss_pred_bias/3., loss_pseudo_pred_bias, step, int(100*i/data_loader.__len__()))\n",
    "                self.logger.info(msg)\n",
    "\n",
    "\n",
    "    def _train_step_baseline(self, data_loader, step):\n",
    "        for i, (images,color_labels,labels) in enumerate(data_loader):\n",
    "            \n",
    "            images = self._get_variable(images)\n",
    "            labels = self._get_variable(labels)\n",
    "\n",
    "            self.optim.zero_grad()\n",
    "            feat_label, pred_label = self.net(images)\n",
    "\n",
    "            # loss for self.net\n",
    "            loss_pred = self.loss(pred_label, torch.squeeze(labels))\n",
    "            loss_pred.backward()\n",
    "            self.optim.step()\n",
    "\n",
    "            # TODO: print elapsed time for iteration\n",
    "            if i % self.option.log_step == 0:\n",
    "                msg = \"[TRAIN] cls loss : %.6f (epoch %d.%02d)\" \\\n",
    "                       % (loss_pred,step,int(100*i/data_loader.__len__()))\n",
    "                self.logger.info(msg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _validate(self, data_loader):\n",
    "        self._mode_setting(is_train=False)\n",
    "        self._initialization()\n",
    "        if self.option.checkpoint is not None:\n",
    "            self._load_model()\n",
    "        else:\n",
    "            print(\"No trained model for evaluation provided\")\n",
    "            import sys\n",
    "            sys.exit()\n",
    "\n",
    "        num_test = 10000\n",
    "\n",
    "        total_num_correct = 0.\n",
    "        total_num_test = 0.\n",
    "        total_loss = 0.\n",
    "        for i, (images,color_labels,labels) in enumerate(data_loader):\n",
    "            \n",
    "            start_time = time.time()\n",
    "            images = self._get_variable(images)\n",
    "            color_labels = self._get_variable(color_labels)\n",
    "            labels = self._get_variable(labels)\n",
    "\n",
    "            self.optim.zero_grad()\n",
    "            _, pred_label = self.net(images)\n",
    "\n",
    "\n",
    "            loss = self.loss(pred_label, torch.squeeze(labels))\n",
    "            \n",
    "            batch_size = images.shape[0]\n",
    "            total_num_correct += self._num_correct(pred_label,labels,topk=1).item()\n",
    "            total_loss += loss.item()*batch_size\n",
    "            total_num_test += batch_size\n",
    "               \n",
    "        avg_loss = total_loss/total_num_test\n",
    "        avg_acc = total_num_correct/total_num_test\n",
    "        msg = \"EVALUATION LOSS  %.4f, ACCURACY : %.4f (%d/%d)\" % \\\n",
    "                        (avg_loss,avg_acc,int(total_num_correct),total_num_test)\n",
    "        self.logger.info(msg)\n",
    "\n",
    "\n",
    "\n",
    "    def _num_correct(self,outputs,labels,topk=1):\n",
    "        _, preds = outputs.topk(k=topk, dim=1)\n",
    "        preds = preds.t()\n",
    "        correct = preds.eq(labels.view(1, -1).expand_as(preds))\n",
    "        correct = correct.view(-1).sum()\n",
    "        return correct\n",
    "        \n",
    "\n",
    "\n",
    "    def _accuracy(self, outputs, labels):\n",
    "        batch_size = labels.size(0)\n",
    "        _, preds = outputs.topk(k=1, dim=1)\n",
    "        preds = preds.t()\n",
    "        correct = preds.eq(labels.view(1, -1).expand_as(preds))\n",
    "        correct = correct.view(-1).float().sum(0, keepdim=True)\n",
    "        accuracy = correct.mul_(100.0 / batch_size)\n",
    "        return accuracy\n",
    "\n",
    "    def _save_model(self, step):\n",
    "        torch.save({\n",
    "            'step': step,\n",
    "            'optim_state_dict': self.optim.state_dict(),\n",
    "            'net_state_dict': self.net.state_dict()\n",
    "        }, os.path.join(self.option.save_dir,self.option.exp_name, 'checkpoint_step_%04d.pth' % step))\n",
    "        print('checkpoint saved. step : %d'%step)\n",
    "\n",
    "    def _load_model(self):\n",
    "        ckpt = torch.load(self.option.checkpoint)\n",
    "        self.net.load_state_dict(ckpt['net_state_dict'])\n",
    "        self.optim.load_state_dict(ckpt['optim_state_dict'])\n",
    "\n",
    "    def train(self, train_loader, val_loader=None):\n",
    "        self._initialization()\n",
    "        if self.option.checkpoint is not None:\n",
    "            self._load_model()\n",
    "\n",
    "        self._mode_setting(is_train=True)\n",
    "        timer = Timer(self.logger, self.option.max_step)\n",
    "        start_epoch = 0\n",
    "        for step in range(start_epoch, self.option.max_step):\n",
    "            if self.option.train_baseline:\n",
    "                self._train_step_baseline(train_loader, step)\n",
    "            else:\n",
    "                self._train_step(train_loader,step)\n",
    "            self.scheduler.step()\n",
    "            self.scheduler_bias.step()\n",
    "\n",
    "\n",
    "            if step == 1 or step % self.option.save_step == 0 or step == (self.option.max_step-1):\n",
    "                if val_loader is not None:\n",
    "                    self._validate(step, val_loader)\n",
    "                self._save_model(step)\n",
    "\n",
    "\n",
    "    def _get_variable(self, inputs):\n",
    "        if self.option.cuda:\n",
    "            return Variable(inputs.cuda())\n",
    "        return Variable(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
